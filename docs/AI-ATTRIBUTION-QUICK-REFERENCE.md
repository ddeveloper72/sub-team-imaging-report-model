# AI Attribution and EU AI Act Compliance - Quick Reference

**Project**: Xt-EHR T7.2 Sub-team for Imaging Reports Model Analysis  
**Last Updated**: November 2025  
**Compliance Framework**: EU Artificial Intelligence Act (Regulation EU 2024/1689)

---

## ü§ñ AI Analysis Attribution Statement

### Standard Attribution Text

For use in publications, presentations, and documentation:

> **AI-Assisted Analysis**: This work was compiled with the assistance of Claude Sonnet 4.5 (Anthropic), a General-Purpose AI model, in accordance with EU AI Act Article 52 transparency requirements. The AI system performed data analysis, pattern recognition, and report compilation for 2,738 real-world imaging reports from the PARROT v1.0 dataset. All findings have been validated against source data and are subject to expert review by healthcare informatics specialists.

### Short Form Attribution

For space-constrained contexts:

> **AI Attribution**: Analysis compiled with Claude Sonnet 4.5 (Anthropic). Validated by domain experts. EU AI Act compliant.

---

## üìã What Was AI-Assisted?

### ‚úÖ AI Involvement

The AI system (Claude Sonnet 4.5) was used for:

1. **Data Analysis**
   - Statistical analysis of 2,738 PARROT v1.0 imaging reports
   - Frequency calculations and usage pattern identification
   - Cross-tabulation of modalities, anatomical areas, and languages

2. **Pattern Recognition**
   - Identification of common data elements across reports
   - Recognition of clinical vs. administrative content patterns
   - Detection of element usage correlations

3. **Comparative Mapping**
   - Mapping between PARROT dataset elements and Xt-EHR model specifications
   - Gap analysis between real-world usage and model completeness
   - Traceability linking between source data and model definitions

4. **Classification Development**
   - Categorization of elements into Basic, Intermediate, and Beyond Basic
   - Evidence-based justification for each classification
   - Implementation complexity assessment

5. **Documentation Generation**
   - Report writing and synthesis
   - Markdown documentation creation
   - Visualization recommendations
   - Executive summaries and technical documentation

### ‚ùå Not AI-Generated

The following were NOT performed by AI:

- Strategic project decisions and scope definition
- Domain expertise and clinical validation
- Final recommendations and policy decisions
- Stakeholder engagement and consensus building
- Legal or regulatory interpretations

---

## üá™üá∫ EU AI Act Compliance Summary

### Risk Classification

**Category**: Limited Risk (Transparency Requirements)

This project is classified as **Limited Risk** under the EU AI Act because:
- It uses AI for research and analysis purposes
- It does NOT make clinical decisions or diagnose patients
- It does NOT directly impact patient safety or care delivery
- It operates with human oversight and expert validation

### Compliance Measures

| Requirement | Status | Implementation |
|-------------|--------|----------------|
| **Article 52: Transparency** | ‚úÖ Compliant | Clear AI attribution in all documents |
| **Article 4: AI Literacy** | ‚úÖ Compliant | Team trained on AI capabilities and limitations |
| **Article 53: GPAI Documentation** | ‚úÖ Compliant | Using Anthropic's Claude (compliant provider) |
| **Human Oversight** | ‚úÖ Compliant | Expert review by Xt-EHR T7.2 Sub-team |
| **Data Protection (GDPR)** | ‚úÖ Compliant | Using anonymized, publicly available datasets |

### Key Timeline Dates

- **2 August 2024**: EU AI Act entered into force ‚úÖ
- **2 February 2025**: Prohibited practices effective ‚úÖ
- **2 August 2025**: GPAI obligations active ‚úÖ
- **2 August 2026**: High-risk AI systems rules ‚ÑπÔ∏è (Not applicable - Limited Risk project)

---

## üìö Reference Resources

### EU AI Act Official Resources

1. **Full Legislation**
   - [Regulation (EU) 2024/1689](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)
   - Official Journal of the European Union

2. **European Commission Guidance**
   - [AI Act Overview](https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai)
   - [European Approach to AI](https://digital-strategy.ec.europa.eu/en/policies/european-approach-artificial-intelligence)
   - [AI Act Service Desk](https://ai-act-service-desk.ec.europa.eu/en)

3. **National Implementation (Ireland)**
   - [Enterprise Ireland AI Act Hub](https://enterprise.gov.ie/en/what-we-do/innovation-research-development/artificial-intelligence/eu-ai-act/)
   - Single Point of Contact: AIinfo@enterprise.gov.ie

### Project Documentation

- **Detailed Compliance**: [EU-AI-ACT-COMPLIANCE.md](EU-AI-ACT-COMPLIANCE.md)
- **Project Overview**: [README.md](../README.md)
- **Executive Summary**: [EXECUTIVE_SUMMARY.md](../EXECUTIVE_SUMMARY.md)
- **All References**: [project-references.md](project-references.md)

---

## üéØ Quick Checklist for Documents

When creating or updating project documents, ensure:

- [ ] AI attribution statement included
- [ ] Reference to Claude Sonnet 4.5 (Anthropic)
- [ ] Note on human oversight and expert validation
- [ ] Link to EU-AI-ACT-COMPLIANCE.md
- [ ] Statement of compliance with Article 52
- [ ] Clear distinction between AI-generated and human-validated content

### Template for New Documents

```markdown
### ü§ñ AI Analysis Attribution

**EU AI Act Compliance**: This [document/analysis/report] was compiled with 
the assistance of **Claude Sonnet 4.5** (Anthropic), a General-Purpose AI 
model, in accordance with Article 52 transparency requirements. All findings 
have been validated against source data and are subject to expert review. 
See [EU-AI-ACT-COMPLIANCE.md](docs/EU-AI-ACT-COMPLIANCE.md) for details.
```

---

## üí° FAQ

### Q: Why do we need AI attribution?

**A**: The EU AI Act (Article 52) requires transparency when AI systems are used, especially in professional contexts like healthcare. Users have the right to know when they're interacting with AI-generated content.

### Q: Is this project considered "high-risk" AI?

**A**: No. While healthcare AI systems CAN be high-risk, this project is research and analysis focused, not clinical decision-making. It's classified as "Limited Risk" requiring transparency but not the full high-risk obligations.

### Q: Do we need to register with any AI authority?

**A**: Not at this stage. The project uses a third-party GPAI model (Claude) whose provider (Anthropic) handles GPAI compliance. Our transparency obligations are met through attribution.

### Q: What if the AI made a mistake in the analysis?

**A**: This is why we have **human oversight**. All AI-generated findings are validated against source data and reviewed by domain experts before being finalized. The AI is a tool, not the decision-maker.

### Q: How long do we need to maintain this compliance?

**A**: As long as the AI-assisted analysis is part of the project. If the work is updated or extended, compliance measures should continue. The AI Act is now permanent EU law.

---

## üìû Contact for Compliance Questions

**Internal Project**: Xt-EHR T7.2 Sub-team governance  
**EU AI Act General**: [AI Act Service Desk](https://ai-act-service-desk.ec.europa.eu/en)  
**Irish Implementation**: AIinfo@enterprise.gov.ie

---

**Document Status**: Reference Guide  
**Version**: 1.0  
**Review Cycle**: Quarterly or upon regulatory updates
